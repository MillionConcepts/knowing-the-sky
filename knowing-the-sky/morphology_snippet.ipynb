{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446fef1e-23c0-482b-add2-e5a235d07f4b",
   "metadata": {},
   "source": [
    "### Introduction to Low-Level Image Processing\n",
    "\n",
    "You can get a long way in image processing and computer vision with\n",
    "fairly simple operations that basically just work with arithmetic.\n",
    "They're not only easier to use than more complex algorithms, but \n",
    "also usually faster, easier to inspect, and more reliable than \n",
    "complex algorithms. \n",
    "\n",
    "It's good to understand low-level techniques if you think you might want \n",
    "to use more complex techniques for image recognition or processing, \n",
    "including machine learning methods, because complex techniques often \n",
    "don't work well without preprocessing by simpler functions. Simple \n",
    "functions can also be assembled into quite complex ones!\n",
    "\n",
    "In those notebook, we'll primarily be using \"morphological\" operations \n",
    "-- operations that work with line, shape, and form. However, we'll start\n",
    "with a little introduction to their extended family.\n",
    "\n",
    "#### Footprint Operations\n",
    "\n",
    "Many image manipulation techniques rely on looking at each pixel in the \n",
    "image, then applying some kind of mathematical function to the pixels \n",
    "that fall within some region around it. This region is called a \"footprint\"\n",
    "(or sometimes a \"kernel\").  \n",
    "\n",
    "Let's look briefly at a couple of _non_-morphological examples of this\n",
    "kind of technique: the median and maximum filters. These filters do pretty\n",
    "much what their names suggest: they replace each pixel with the median or \n",
    "maximum value of the surrounding pixels within a footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b075d-d059-42d5-b9c4-8e4b999f5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# NOTE: I don't remember if we opened 'desktop' images before.\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndi\n",
    "# This is a little settings file that removes all the annoying\n",
    "# borders and axes and things that aren't really relevant\n",
    "# when we're just using matplotlib to look at things as images.\n",
    "plt.style.use('settings/simple_image.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587859cb-6122-4141-9944-47fbc72b8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a noisy cross shape.\n",
    "noisecross = np.asarray(Image.open('images/noisecross.png'))\n",
    "_ = plt.imshow(noisecross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90b416-375e-4c68-882e-16004ce94754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate big and small footprints.\n",
    "# note that what's 'big' and 'small' depends on the\n",
    "# size of the image you're applying a filter to!\n",
    "fbig, fsmall = 10, 3\n",
    "big_foot, small_foot = np.ones((fbig, fbig)), np.ones((fsmall, fsmall))\n",
    "# these are just arrays:\n",
    "small_foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2812eb6-1cc2-4efb-aa31-7ad35a62461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median filter has a 'softening' effect. When the footprint is small, the \n",
    "# softening is relatively mild; as it gets bigger, the softening gets more intense.\n",
    "# This is a little bit like turning up the bass on a piece of music: it emphasizes\n",
    "# more consistent parts of the image and suppresses more variable ones.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "axes[0].imshow(noisecross)\n",
    "axes[1].imshow(ndi.median_filter(noisecross, footprint=small_foot))\n",
    "axes[2].imshow(ndi.median_filter(noisecross, footprint=big_foot))\n",
    "for i, title in zip((0, 1, 2), (\"original\", \"median_small\", \"median_big\")):\n",
    "    axes[i].set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efbb64-708b-482a-aba1-8d9c05517b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be used for many practical purposes. For instance, look \n",
    "# at what a median filter can do to the scanlines in this classic Viking Orbiter image\n",
    "# (a technique the ground team used to great advantage!):\n",
    "import pdr\n",
    "viking = pdr.read(\"/datascratch/viking/edr/vo_1023/f611axx/F611A13.IMG\").IMAGE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 9))\n",
    "axes[0].imshow(viking)\n",
    "axes[1].imshow(ndi.median_filter(viking, footprint=np.ones((4, 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a36e-58bd-4888-bb28-e0ba5a077e82",
   "metadata": {},
   "source": [
    "### Making Binary Images\n",
    "\n",
    "Because subjective fullness of the Moon is basically about shape and line,\n",
    "we'd like to be able to work directly with those aspects of images. \n",
    "Morphological operators are powerful tools for doing this. Morphological\n",
    "operators are a type of footprint-based filter, that use logical operations\n",
    "like \"and\" and \"or\" instead of arithmetic.\n",
    "\n",
    "This means that they want to work on \"binary\" images -- black and white \n",
    "images made up of only 1s and 0s.\n",
    "\n",
    "Most images we want to work with don't start out as binary images. The\n",
    "easiest (and one of the most effective) ways to reduce images to lines\n",
    "is to set a cutoff value or \"threshold\". We then set all values below\n",
    "that threshold to black, and all values above that threshold to white. \n",
    "If it's a color image, we also want to turn it to grayscale first.\n",
    "This often works something like tracing or making an outline of an image --\n",
    "and these are also good first steps in other processes that want outlines,\n",
    "like silkscreening.\n",
    "\n",
    "Let's go ahead and walk through the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b6788-d657-429b-8783-38d88640a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a detail of part of a Tiffany lamp.\n",
    "tiffany = np.asarray(Image.open(\"images/tiffany.png\"))\n",
    "plt.imshow(tiffany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d0668-7581-4f61-b95f-6e436ab2ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color images are usually 3-D arrays where the third axis\n",
    "# represents color channel, in this case red (R), green (G) or blue (B).\n",
    "# This would make a purple version of the image:\n",
    "purple_tiffany = tiffany.copy()\n",
    "purple_tiffany[:, :, 1] = 0\n",
    "plt.imshow(purple_tiffany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd70672-d13b-4150-ba47-62332f2258b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that the easiest way to make a gray version of a color image\n",
    "# is just to merge its channels down:\n",
    "tiffany_gray = np.median(tiffany, axis=2)\n",
    "plt.imshow(tiffany_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041f3fe-dd5b-46e9-8434-72c89cc59d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now turn it to a black-and-white image with thresholding.\n",
    "# Picking the correct threshold value is a little bit of an art and\n",
    "# depends on exactly what features you want the outline to\n",
    "# retain. Let's see what happens at a few different levels...\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 8))\n",
    "threshold_levels = (10, 50, 160)\n",
    "for i, level in enumerate(threshold_levels):\n",
    "    axes[i].imshow(tiffany_gray > level)\n",
    "    axes[i].set_title(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff68d2-1db1-4e03-9cd3-0fe903e61c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and pick the middle value for our outline.\n",
    "tiffany_outline = tiffany_gray > 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56b709-b3d5-4fb1-ba11-b0e3b9ccfa3f",
   "metadata": {},
   "source": [
    "### Morphological Operators\n",
    "\n",
    "There are really only two morphological operators: dilation and erosion. \n",
    "Others are made up of combinations of these in different orders.\n",
    "\n",
    "Dilation is an \"or\". If there is a pixel valued 1 anywhere in the dilation \n",
    "operator's footprint, it sets the center pixel to 1; otherwise, it sets it\n",
    "to 0. Erosion is an \"and\": if _all_ pixels in the erosion operator's \n",
    "footprint are 1, it sets the center pixel to 1; otherwise, it sets the\n",
    "center pixel to 0.\n",
    "\n",
    "This means that erosion will tend to make black parts of the image heavier,\n",
    "thicker, and more coherent, and dilation will do the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d160aa-97a3-47b2-b5e0-fe6ee3bff0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like the median filter we saw earlier, bigger footprints tend to make\n",
    "# morphological operations \"stronger\".\n",
    "\n",
    "# Because this particular image is basically a black-on-white outline, erosion \n",
    "# will tend to make its lines thicker and its sections more distinct:\n",
    "small, big = 4, 9\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 8))\n",
    "for i, size in enumerate((small, big)):\n",
    "    footprint = np.ones((size, size))\n",
    "    axes[i].imshow(ndi.binary_erosion(tiffany_outline, footprint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf055b71-69d0-4f1a-abfe-13d28cc20c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whereas dilation will tend to make its lines thinner and blur sections:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 8))\n",
    "for i, size in enumerate((small, big)):\n",
    "    footprint = np.ones((size, size))\n",
    "    axes[i].imshow(ndi.binary_dilation(tiffany_outline, footprint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203393f-e9d6-4a96-838e-cb76fac4451e",
   "metadata": {},
   "source": [
    "### Labeling\n",
    "\n",
    "Being able to manipulate line like this is very useful in part because it\n",
    "enables us to easily define -- and find -- contiguous regions of an image.\n",
    "This process is called \"labeling\", and it is a powerful way to segment\n",
    "images and extract regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafb7a1-d122-4933-88cb-f9b1aa1f6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and work with the thicker outline based on the\n",
    "# size-9 footprint:\n",
    "trace = ndi.binary_erosion(tiffany_outline, np.ones((9, 9)))\n",
    "# The 'label' function will give every contiguous 1-valued region \n",
    "# its own unique number. Note how it cuts the sections at the \n",
    "# edges off, and can't quite distinguish some regions that might\n",
    "# look contiguous to your eye because of some junky little line bits\n",
    "# that connect them:\n",
    "labels, n_labels = ndi.label(trace)\n",
    "plt.imshow(labels, cmap='tab20', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6206fb1-366e-41b6-baa3-82176a38efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this to pick out, count, and locate individual\n",
    "# regions of an image. Try running this cell a few times.\n",
    "# You'll note that not every label is interesting -- the algorithm\n",
    "# will happily assign a unique label to even a tiny little dot.\n",
    "selected = np.isin(labels, np.random.choice(np.unique(labels), 8))\n",
    "plt.imshow(\n",
    "    np.where(selected, labels, 0), cmap='Dark2_r', interpolation=\"none\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
