{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446fef1e-23c0-482b-add2-e5a235d07f4b",
   "metadata": {},
   "source": [
    "## Notes on Low-Level Image Processing\n",
    "\n",
    "You can get a long way in image processing and computer vision with\n",
    "fairly simple operations that basically just work with arithmetic.\n",
    "They're not only easier to use than more complex algorithms, but \n",
    "also usually faster, easier to inspect, and more reliable than \n",
    "complex algorithms. \n",
    "\n",
    "It's good to understand low-level techniques if you think you might want \n",
    "to use more complex techniques for image recognition or processing, \n",
    "including machine learning methods, because complex techniques often \n",
    "don't work well without preprocessing by simpler functions. Simple \n",
    "functions can also be assembled into quite complex ones.\n",
    "\n",
    "### Footprint Operations\n",
    "\n",
    "Many image manipulation techniques rely on looking at each pixel in the \n",
    "image, then applying some kind of mathematical function to the pixels \n",
    "that fall within some region around it. This region is called a \"footprint\"\n",
    "(or sometimes a \"kernel\"). One of the simplest examples is the _median filter_.\n",
    "It by replacing each pixel in an image with the median value of the pixels that \n",
    "fall within a footprint around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b075d-d059-42d5-b9c4-8e4b999f5908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# NOTE: I don't remember if we opened 'desktop' images before.\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# NOTE: importing custom convenience functions is a little cheaty, but\n",
    "# removes SO MUCH boilerplate...and teaching the matplotlib API in detail \n",
    "# is not the goal of this notebook. We could also publish it somewhere.\n",
    "# It's trimmed down from moonbow basically\n",
    "\n",
    "# convenience function for displaying multiple images at once\n",
    "from ktsutils.mpl import imshow_multiple\n",
    "\n",
    "# Settings file that removes all the borders and axes and things \n",
    "# that aren't really relevant when we're just using matplotlib to\n",
    "# look at arrays as images.\n",
    "plt.style.use('settings/simple_image.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587859cb-6122-4141-9944-47fbc72b8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a noisy cross shape.\n",
    "noisecross = np.asarray(Image.open('images/noisecross.png'))\n",
    "_ = plt.imshow(noisecross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90b416-375e-4c68-882e-16004ce94754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate big and small footprints. note that what's 'big' and 'small'\n",
    "# depends on the size of the image you're applying a filter to!\n",
    "fbig, fsmall = 10, 3\n",
    "big_foot, small_foot = np.ones((fbig, fbig)), np.ones((fsmall, fsmall))\n",
    "# these are just arrays:\n",
    "small_foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2812eb6-1cc2-4efb-aa31-7ad35a62461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The median filter has a 'softening' effect. When the footprint is small, the \n",
    "# softening is relatively mild; as it gets bigger, the softening gets more intense.\n",
    "# This is a little bit like turning up the bass on a piece of music: it emphasizes\n",
    "# more consistent parts of the image and suppresses more variable ones.\n",
    "nc_small_median = ndi.median_filter(noisecross, footprint=small_foot)\n",
    "nc_big_median = ndi.median_filter(noisecross, footprint=big_foot)\n",
    "_ = imshow_multiple(\n",
    "    [noisecross, nc_small_median, nc_big_median],\n",
    "    titles = (\"original\", \"median_small\", \"median_big\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efbb64-708b-482a-aba1-8d9c05517b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be used for many practical purposes. For instance, look \n",
    "# at what a median filter can do to the scanlines in this classic Viking Orbiter image\n",
    "# (a technique the ground team used to great advantage!):\n",
    "import pdr\n",
    "\n",
    "viking = pdr.read(\"/datascratch/viking/edr/vo_1023/f611axx/F611A13.IMG\").IMAGE\n",
    "_ = imshow_multiple(\n",
    "    [viking, ndi.median_filter(viking, footprint=np.ones((4, 4)))],\n",
    "    base_figsize=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a36e-58bd-4888-bb28-e0ba5a077e82",
   "metadata": {},
   "source": [
    "## Morphological Operators\n",
    "\n",
    "Because subjective fullness of the Moon is basically about shape and line,\n",
    "we'd like to be able to work directly with those aspects of images. \n",
    "Morphological operators are powerful tools for doing this. Morphological\n",
    "operators are a type of footprint-based filter that use logical operations\n",
    "like \"and\" and \"or\" instead of arithmetic.\n",
    "\n",
    "### Making Binary Images\n",
    "\n",
    "Because they do true/false logic, morphological operators want to work on\n",
    "\"binary\" images -- black-and-white images made up of only 1s and 0s.\n",
    "\n",
    "Most images we want to work with don't start out as binary images. The\n",
    "easiest (and one of the most effective) ways to reduce images to lines\n",
    "is to set a cutoff value or \"threshold\". We then set all values below\n",
    "that threshold to black, and all values above that threshold to white. \n",
    "If it's a color image, we also want to turn it to grayscale first.\n",
    "This often works something like tracing or making an outline of an image --\n",
    "and these are also good first steps in other processes that want outlines,\n",
    "like silkscreening.\n",
    "\n",
    "Let's go ahead and walk through the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b6788-d657-429b-8783-38d88640a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a detail of part of a Tiffany lamp.\n",
    "tiffany = np.asarray(Image.open(\"images/tiffany.png\"))\n",
    "_ = plt.imshow(tiffany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d0668-7581-4f61-b95f-6e436ab2ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color images are usually 3-D arrays where the third axis\n",
    "# represents color channel, in this case red (R), green (G) or blue (B).\n",
    "# This would make a purple version of the image:\n",
    "purple_tiffany = tiffany.copy()\n",
    "purple_tiffany[:, :, 1] = 0\n",
    "_ = plt.imshow(purple_tiffany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd70672-d13b-4150-ba47-62332f2258b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The easiest way to make a gray version of a color image is \n",
    "# just to merge its channels down, which can be as simple as\n",
    "# taking their mean or median:\n",
    "tiffany_gray = np.mean(tiffany, axis=2)\n",
    "_ = plt.imshow(tiffany_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041f3fe-dd5b-46e9-8434-72c89cc59d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now turn it to a black-and-white image with thresholding.\n",
    "# Picking the correct threshold value is a little bit of an art and\n",
    "# depends on exactly what features you want the outline to\n",
    "# retain. Let's see what happens at a few different levels...\n",
    "threshold_levels = (10, 25, 50, 160)\n",
    "outlines = [tiffany_gray > level for level in threshold_levels]\n",
    "_ = imshow_multiple(outlines, titles=threshold_levels, base_figsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff68d2-1db1-4e03-9cd3-0fe903e61c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the second one for our outline -- but \n",
    "# you might to try the next steps a few times with different\n",
    "# settings to see what happens.\n",
    "tiffany_outline = tiffany_gray > 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56b709-b3d5-4fb1-ba11-b0e3b9ccfa3f",
   "metadata": {},
   "source": [
    "### Dilation and Erosion\n",
    "\n",
    "There are two basic morphological operators: erosion and dilation. Most\n",
    "other can be assembled from combinations of these two.\n",
    "\n",
    "Dilation is an \"or\". If there is a pixel valued 1 anywhere in the dilation \n",
    "operator's footprint, it sets the center pixel to 1; otherwise, it sets it\n",
    "to 0. Erosion is an \"and\": if _all_ pixels in the erosion operator's \n",
    "footprint are 1, it sets the center pixel to 1; otherwise, it sets the\n",
    "center pixel to 0.\n",
    "\n",
    "This means that erosion will tend to make black parts of the image heavier,\n",
    "thicker, and more coherent, and dilation will do the opposite.\n",
    "\n",
    "Let's look at erosion and dilation here. Note that, just like the median filter \n",
    "we saw earlier, bigger footprints tend to make morphological operatorsand selecting the correct footprint size\n",
    "or shape for particular images and applications can be a very finicky job. \"stronger\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d160aa-97a3-47b2-b5e0-fe6ee3bff0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because this particular image is basically a black-on-white outline, erosion \n",
    "# will tend to make its lines thicker and its sections more distinct:\n",
    "sizes = [4, 9]   \n",
    "eroded = [\n",
    "    ndi.binary_erosion(tiffany_outline, np.ones((fs, fs)))\n",
    "    for fs in sizes\n",
    "]\n",
    "_ = imshow_multiple(eroded, titles=[f\"erosion {s}\" for s in sizes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf055b71-69d0-4f1a-abfe-13d28cc20c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whereas dilation will tend to make its lines thinner and blur sections:\n",
    "dilated = [\n",
    "    ndi.binary_dilation(tiffany_outline, np.ones((fs, fs)))\n",
    "    for fs in sizes\n",
    "]\n",
    "_ = imshow_multiple(dilated, titles=[f\"dilation {s}\" for s in sizes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203393f-e9d6-4a96-838e-cb76fac4451e",
   "metadata": {},
   "source": [
    "## Labeling\n",
    "\n",
    "Being able to manipulate lines like this is very useful in part because it\n",
    "helps us break images up into meaningful pieces. The simplest way to do this is to\n",
    "simply find matching regions of the image and assign a unique number to \n",
    "them. This process is called \"labeling\", and many good tools for it exist\n",
    "in Python.\n",
    "\n",
    "In the next cell, you'll 'thicken' the Tiffany outline and then use `ndi.label()` \n",
    "to assign every connected 1-valued region of that outline its own unique number.\n",
    "It always assigns 0 to what it identifies as \"background\". \n",
    "You'll see that it doesn't work perfectly -- it may cut some sections at the \n",
    "edges off, and can't quite distinguish some regions that might look contiguous to \n",
    "your eye because of some junky little line bits that connect them.\n",
    "\n",
    "Like threshold levels, selecting good footprint sizes and shapes for particular images\n",
    "and applications can be a very finicky job. If you change the footprint size\n",
    "from (3, 3) and run the cell again, you will see that you get quite different labels.\n",
    "If you make it a lot bigger, you'll see that you get _fewer_ labels, because the erosion\n",
    "will have made image areas more distinct from one another...although if you make it big \n",
    "enough, you might not get any at all, because you'll have eroded all the lines into one\n",
    "big line. You'll also get very different results -- probably _much_ larger and more \n",
    "connected labels -- if you swap it to binary dilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafb7a1-d122-4933-88cb-f9b1aa1f6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = ndi.binary_erosion(tiffany_outline, np.ones((3, 3)))\n",
    "labels, n_labels = ndi.label(trace)\n",
    "print(f\"{n_labels} labels found.\")\n",
    "plt.imshow(np.ma.masked_where(labels == 0, labels), cmap='flag', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8c8fa-1c10-4796-9477-5472c7ceddcc",
   "metadata": {},
   "source": [
    "We can use this to pick out, count, and locate individual\n",
    "regions of an image. Try running this next cell a few times to drill\n",
    "down into the specific image elements our little algorithm identified.\n",
    "You'll note that not every label is interesting -- `ndi.label()`\n",
    "will happily assign a unique label to a tiny little dot, as long\n",
    "as it's isolated. When we look at lunar images a little later, \n",
    "we'll need to watch for that fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6206fb1-366e-41b6-baa3-82176a38efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for visualization.\n",
    "\n",
    "def apply_2d_stencil(color_image, stencil_2d):\n",
    "    # reshape `stencil_2d` to fit the 3D color image\n",
    "    stencil_3d = np.moveaxis(np.tile(stencil_2d, (3, 1, 1)), 0, 2)\n",
    "    # return a 3D array that contains the original pixels where \n",
    "    # `stencil_2d` is truthy, and is black elsewhere\n",
    "    return np.where(stencil_3d, color_image, 0)\n",
    "\n",
    "def labelstencil(color_image, label_array, label_numbers):\n",
    "    \"\"\"\n",
    "    Return a copy of `color_image` blacked out wherever the values of \n",
    "    `label_array` don't fall within `label_numbers`.\n",
    "    \"\"\"\n",
    "    # make an array that's True for these labels and false otherwise\n",
    "    return apply_2d_stencil(color_image, np.isin(label_array, label_numbers))\n",
    "\n",
    "\n",
    "# select 8 random numbers from among all labels, not counting the \n",
    "# 0/background label.\n",
    "random_label_choices = np.random.choice(range(1, n_labels), 8)\n",
    "fig, ax = plt.subplots(figsize=(5, 7))\n",
    "ax.imshow(labelstencil(tiffany, labels, random_label_choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398c58d-adf6-4a73-991c-5d39421b155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also look at just the background:\n",
    "fig, ax = plt.subplots(figsize=(5, 7))\n",
    "ax.imshow(labelstencil(tiffany, labels, [0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8aaecc-8a22-4a54-a152-acd061fb3dc3",
   "metadata": {},
   "source": [
    "### Getting shapes from labels\n",
    "\n",
    "Because of image defects and the messy imperfection of the world,\n",
    "labels don't usually _exactly_ fit the regions you'd like to find\n",
    "in images, and they also often have very complex boundaries that \n",
    "make some kinds of analysis harder (even when the actual objects \n",
    "in the scene don't). One straightforward technique that's effective\n",
    "in many situations is simply to draw some simple geometric shape \n",
    "like a circle or rectangle around the label. (Sometimes you're not\n",
    "looking for simple geometric shapes, of course, in which case this\n",
    "would not be a good idea.)\n",
    "\n",
    "\n",
    "OpenCV has several fast, reliable functions for doing this.\n",
    "Its Python wrapper, `cv2`, is very effective, but its expectations \n",
    "are unusual and its error messages aren't always very readable (it's \n",
    "practically like a separate language). Rather than spend the rest of \n",
    "this Notebook talking about the OpenCV API, we've provided\n",
    "a couple of example functions in the next cell for performing common \n",
    "tasks of this kind with `cv2`.\n",
    "\n",
    "\n",
    "**DEV NOTE: Again, cheaty. But actually explaining why you have to do all this \n",
    "array manipulation and type conversion to use even simple functions from \n",
    "the OpenCV API -- and then how each function works, which is weirdly different --\n",
    "will legitimately take like half a Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c00caa-af9f-4ab1-8e6f-7a1ac3d99367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktsutils.opencv import mask2shape\n",
    "\n",
    "# and a simple example:\n",
    "random_label_choices = np.random.choice(range(1, n_labels), 8)\n",
    "assembled = np.zeros_like(tiffany)\n",
    "for label in random_label_choices:\n",
    "    # can also be \"circle\" or \"rectangle\"\n",
    "    _, drawn = mask2shape(labels == label, \"triangle\", thickness=7)\n",
    "    assembled += drawn\n",
    "fig, ax = plt.subplots(figsize=(5, 6))\n",
    "ax.imshow(\n",
    "    np.clip(assembled + labelstencil(tiffany, labels, random_label_choices), 0, 255)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69969b46-b856-41e4-88eb-aea72e296d6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SECTIONS SECTIONS SECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f92720-d906-46e2-ac73-97f62e7384a4",
   "metadata": {},
   "source": [
    "# Moon fullness identification algorithm\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "These are not completely true, but good enough for the algorithm:\n",
    "1. A full Moon looks like a perfect circle.\n",
    "2. The only things that ever appear in the GOES LUN images are stars, the Moon, the Earth, and static.\n",
    "3. The Earth will always appear as a contiguous region that touches at least one image edge.\n",
    "4. If the Moon touches an image edge, we can ignore it, because we won't be able to tell how full\n",
    "   it is anyway.\n",
    "5. The images are taken at about the same distance from the Moon, so the Moon will fall within a\n",
    "   small size range.\n",
    "6. There are no legitimate images of the Moon at less than half full in this set, so we can\n",
    "   always assume the Moon label is convex.\n",
    "\n",
    "## Steps\n",
    "\n",
    "Given those assumptions, we can perform the following steps to figure out how full\n",
    "the Moon looks in a GOES image:\n",
    "\n",
    "1. Load the image.\n",
    "2. Turn it into a black-and-white \"outline\" using thresholding.\n",
    "3. Apply an erosion operator to the outline to clean up static, stars, and imaging imperfections.\n",
    "4. Label the eroded outline, then exclude labels that are either the wrong size or too close to\n",
    "   an image edge. If we have exactly one label left after this, it's the Moon; proceed to step 5.\n",
    "   Otherwise, there's no Moon in the image; stop the algorithm.\n",
    "6. Apply a dilation operator to smooth the edges of the Moon label, and then \n",
    "7. Draw a circle around the label. The ratio of the area of that circle to the that ratio is\n",
    "   fullness.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "First, we'll build the algorithm step by step together -- but this time, we'll be asking _you_ to \n",
    "w\u0000e\u0000 appropriate parameters for the functions. Hints are available, but there's no strict\n",
    "right answer to this -- different sets of parameters might work equally well, and some might\n",
    "work better on some images and worse on others.\n",
    "\n",
    "Then, we'll try the algorithm on all the images and test it against \"ground truth\". If you don't\n",
    "like the results you get, then you can go back and tweak your parameters until you do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfff84-54b4-4e4b-9815-477a120ef22b",
   "metadata": {},
   "source": [
    "### Algorithm step 1: Load the image \n",
    "\n",
    "There's not much fancy to do here. The main thing to take note of is that\n",
    "the filters we're working with do _not_ like masked arrays, but NetCDF4 uses\n",
    "masks to represent bad values. This wouldn't work in every application, but\n",
    "in these images, we can get away with just setting every masked element to 0\n",
    "and throwing the mask away by using the `.filled(fill_value)` method of numpy\n",
    "masked arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3aece-cf68-4c7a-b1ba-4850a2c53445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "def load_goes_image(path):\n",
    "    array = Dataset(path).variables['radiance'][:]\n",
    "    return array.filled(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab02975-5e1b-40a9-85d0-0465053f13d5",
   "metadata": {},
   "source": [
    "### Pick images for pipeline tuning\n",
    "\n",
    "Go ahead and use this function to load in some test images so\n",
    "that you can tune the rest of the pipeline effectively.\n",
    "\n",
    "You probably want to pick at least one that contains a clear image \n",
    "of the Moon and one that doesn't. You could even just pick random\n",
    "ones until you see ones you like -- this is often a good idea for\n",
    "testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccd7d4-8286-460e-8b65-6276c75d4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "LUN_FOLDER = Path(\"/datascratch/goes_subset_flat/\")\n",
    "goes_lun_index = pd.read_csv(\"indices/lun_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133734c6-efb0-4e84-9040-99491ea01c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, n_images = [], 3\n",
    "for ix in random.choices(goes_lun_index.index, k=n_images):\n",
    "    path = LUN_FOLDER / goes_lun_index.loc[ix, 'name']\n",
    "    images.append(load_goes_image(path))\n",
    "_ = imshow_multiple(images, base_figsize=9, direction=\"column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a3f2a-fcc4-4c17-9d36-c77e3dc40574",
   "metadata": {},
   "source": [
    "# Algorithm step 2: Make an outline of the image\n",
    "\n",
    "This is just like the Tiffany lamp, except these images are already\n",
    "grayscale, so it's _very_ simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0bf42-e8ca-49c2-9057-7abf19449592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_outline(image, threshold):\n",
    "    return image > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b4e13-744f-4bce-9c73-3709b1320212",
   "metadata": {},
   "source": [
    "### Tune the threshold value\n",
    "\n",
    "Find a value for THRESHOLD that produces a sensible result on your\n",
    "test images. Too low and you'll get too much noise in the outline;\n",
    "too high and you won't get enough of the Moon (or not reliably, \n",
    "depending on exposure time).\n",
    "\n",
    "As a starting point, remember that the threshold value will want\n",
    "going to be between the `.min()` and `.max()` of the image,\n",
    "or it's going to just make the \"outline\" all white or all black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05511e68-8154-49e4-bdc5-0c1d9e2cdc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THRESHOLD = some number\n",
    "\n",
    "outlines = [make_outline(i, THRESHOLD) for i in images]\n",
    "# this is a quick way to look at the effects of the function, but in this \n",
    "# step as well as later ones, you might also want to stop and examin3\n",
    "# individual images at larger sizes.\n",
    "_ = imshow_multiple(outlines, direction=\"column\", base_figsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d2ab3-b138-4f5d-9dc1-48088d893847",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Algorithm step 3: Clean up the image\n",
    "\n",
    "You'll probably have at least some stars and noise and jaggy scanline stuff \n",
    "in your thresholded images, even if they're not immediately obvious (you might\n",
    "want to look at the images in a bigger form). These can make labeling slower \n",
    "and less reliable. This function simply applies a binary erosion operator to \n",
    "try to clean these up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c376c-e046-48cd-baaf-1d04910478e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode(image, erosion_size):\n",
    "    if erosion_size is None:\n",
    "        return image\n",
    "    return ndi.binary_erosion(image, np.ones((erosion_size, erosion_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51e398-5129-48ff-b4e4-1c699b7add5b",
   "metadata": {},
   "source": [
    "### Start assembling the handler function\n",
    "\n",
    "Now that we have two steps past the plain loading part, \n",
    "we'll want to roll them together so that we can run them all \n",
    "at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bee8a-cec1-4a2c-8fd1-1000ba38f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullness_algorithm_3(image, threshold, erosion_size):\n",
    "    outline = make_outline(image, threshold)\n",
    "    return erode(outline, erosion_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54bb5f-146b-4c6e-9084-f0841231376b",
   "metadata": {},
   "source": [
    "### Tune the erosion operator\n",
    "\n",
    "Find a good value for `EROSION_SIZE` that cleans some defects without getting\n",
    "rid of shapes you'd like to keep.\n",
    "\n",
    "It's often a good idea, when you're designing an algorithm like this, \n",
    "to allow yourself to try turning on and off individual steps that _might_ not \n",
    "be necessary (things like file loading obviously don't count), so `erode` has \n",
    "a provision for turning the step off if you'd like to try that: `EROSION_SIZE=None` \n",
    "and move on.\n",
    "\n",
    "Also keep in mind that all these parameters work together, so you may want to change\n",
    "your mind about what you set for THRESHOLD as you're working here.\n",
    "\n",
    "*NOTE: A possible alternative to this step, if you want to play around with the \n",
    "algorithm a little more, is to apply a median filter _before_ making the outline.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc353da-f58d-4722-80b0-568a10f21bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EROSION_SIZE = some number\n",
    "\n",
    "processed = [\n",
    "    fullness_algorithm_3(\n",
    "        image, threshold=THRESHOLD, erosion_size=EROSION_SIZE\n",
    "    )\n",
    "    for image in images\n",
    "]\n",
    "# again, you might want to look at these individually at larger size as well.\n",
    "_ = imshow_multiple(processed, base_figsize=10, direction=\"column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5574f40-440a-4d81-bf95-3a23d01eabfb",
   "metadata": {},
   "source": [
    "### Algorithm step 4: Label the outline and filter out \"bad\" labels.\n",
    "\n",
    "Making a label array is easy at this point, but to apply our assumptions that the \n",
    "the Moon has a certain minimum extent within the image and that the Moon does not touch \n",
    "an image edge, we need to work with the _indices_ of the labels. Let's go ahead and define\n",
    "a little utility function that produces those along with the label array. (This \n",
    "definitely isn't the most efficient way to do it, but it makes it easy to inspect.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e07d3-fc6a-4acc-b765-b9c6add1fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed_label(arr):\n",
    "    labels, n_labels = ndi.label(arr)\n",
    "    label_indices = {}\n",
    "    for l in range(n_labels + 1):  # we'd like to get 0 as well, just for fun\n",
    "        # np.nonzero() produces a tuple of ndarrays.\n",
    "        y_indices, x_indices = np.nonzero(labels == l)\n",
    "        label_indices[l] = {'y': y_indices, 'x': x_indices}\n",
    "    return labels, label_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2d9e81-dc82-45d2-94aa-f5e500085a6c",
   "metadata": {},
   "source": [
    "#### Create label filters\n",
    "\n",
    "Now we can iterate over all the labels and look at how big each one is and\n",
    "where it's positioned.\n",
    "\n",
    "We can use this to create two filtering functions for the labels: one that\n",
    "rejects small labels and one that rejects labels close to an image edge.\n",
    "We'll also have each of these functions output status codes so we know _why_\n",
    "the pipeline rejects the labels it rejects.\n",
    "\n",
    "**side notes:**\n",
    "\n",
    "* The width and height values basically check dimensions of a bounding\n",
    "non-rotated rectangle for each label, but since we're only concerned with\n",
    "extent and position at this stage, we don't need to actually _make_ the rectangles.\n",
    "A more sophisticated version of this algorithm might, though.\n",
    "* We don't want to construct circles here. One of the things\n",
    "we're doing by putting a lower limit on both width and height is expressing\n",
    "ideas like \"oh that could definitely not be a circle; it is way too long and\n",
    "thin.\" This is a good example of a step where you _shouldn't_ enforce the\n",
    "shapes you're looking for on labels -- they're not ready for that yet!\n",
    "* It's inefficient to actually run every set of indices through every\n",
    "check -- we could stop as soon as a label hit width, or height, or an edge,\n",
    "etc. We're just doing this because it makes it easier to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c992e29-88d5-4ca4-b547-f54320ad5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_label_size(indices, min_width, min_height):\n",
    "    exclusions = []\n",
    "    # np.ptp(arr) is shorthand for arr.max() - arr.min()\n",
    "    if min_width is not None and np.ptp(indices['x']) < min_width:\n",
    "        exclusions.append('width')\n",
    "    if min_height is not None and np.ptp(indices['y']) < min_height:\n",
    "        exclusions.append('height')\n",
    "    return exclusions\n",
    "\n",
    "def filter_label_edge(indices, array_shape, edge_size):\n",
    "    if edge_size is None:\n",
    "        return []\n",
    "    exclusions = []\n",
    "    if (indices['x'] <= edge_size).any():\n",
    "        exclusions.append('left')\n",
    "    if (array_shape[1] - indices['x'] <= edge_size).any():\n",
    "        exclusions.append('right')\n",
    "    if (indices['y'] <= edge_size).any():\n",
    "        exclusions.append('top')\n",
    "    if (array_shape[0] - indices['y'] <= edge_size).any():\n",
    "        exclusions.append('bottom')\n",
    "    return exclusions\n",
    "    \n",
    "def check_labels(\n",
    "    label_indices, array_shape, min_width, min_height, edge_size\n",
    "):\n",
    "    \"\"\"\n",
    "    Handler function that runs filter_label_size() and filter_label_edge()\n",
    "    on a collection of label indices.\n",
    "    Returns a dict of lists giving the exclusions each label hit. If\n",
    "    a label passed all the tests, its list will be empty.\n",
    "    \"\"\"\n",
    "    label_statuses = {}\n",
    "    for label, indices in label_indices.items():\n",
    "        label_statuses[label] = (\n",
    "            filter_label_size(indices, min_width, min_height)\n",
    "            + filter_label_edge(indices, array_shape, edge_size)\n",
    "        )\n",
    "    return label_statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6faa5-9419-448b-84ea-fe1620bc5316",
   "metadata": {},
   "source": [
    "#### Add label filters to the handler function\n",
    "\n",
    "We can put this label-checking step right after the threshold \n",
    "and erosion steps. Drawing on our assumption that there will be\n",
    "at most one Moon in the image, we can also add statements to \n",
    "reject an image if it has no ok labels (no Moon in the image, or\n",
    "something wrong with the algorithm) or more than one ok label \n",
    "(something wrong with the algorithm).\n",
    "\n",
    "Now that we actually might reject an image, we'll also add \n",
    "additional information to the function's return value so we can\n",
    "inspect the algorithm more easily if it's not working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0e434-4e1c-48ce-9f4a-b80a25686eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_labels(label_statuses):\n",
    "    \"\"\"encapsulates the rule that we must have exactly one Moon in an image.\"\"\"\n",
    "    ok_labels = [\n",
    "        i for i, exclusions in label_statuses.items() if exclusions == []\n",
    "    ]\n",
    "    if len(ok_labels) == 0:\n",
    "        return \"no Moon\", None\n",
    "    elif len(ok_labels) > 1:\n",
    "        return \"ambiguous Moon\", None\n",
    "    return \"ok\", ok_labels[0]\n",
    "\n",
    "def fullness_algorithm_4(\n",
    "    image, \n",
    "    threshold, \n",
    "    erosion_size,\n",
    "    min_width,\n",
    "    min_height,\n",
    "    edge_size\n",
    "):\n",
    "    outline = make_outline(image, threshold)\n",
    "    eroded = erode(outline, erosion_size)\n",
    "    labels, label_indices = indexed_label(eroded)\n",
    "    label_statuses = check_labels(\n",
    "        label_indices, image.shape, min_width, min_height, edge_size\n",
    "    )\n",
    "    # 'status' is the overall status of the algorithm.\n",
    "    # 'moonlabel' is the number of the label the algorithm identified as \n",
    "    # corresponding to the Moon, or None if it didn't find the Moon.\n",
    "    status, moonlabel = filter_labels(label_statuses)\n",
    "    return {\n",
    "        \"status\": status,\n",
    "        \"moonlabel\": moonlabel,\n",
    "        \"label_statuses\": label_statuses,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72048ac5-cdd5-4e12-b022-3b49a196b52c",
   "metadata": {},
   "source": [
    "### Assign exclusion criteria and test Moon identification\n",
    "\n",
    "Now we can simply assign these exclusion criteria and see\n",
    "if the algorithm can find the Moon -- and adjust them if it\n",
    "can't. In order to pick values for `MAX_WIDTH`, `MAX_HEIGHT`,\n",
    "and `EDGE_SIZE`, you'll probably want to eyeball the pixel extents \n",
    "of things in the LUN images. If you want to do that in this\n",
    "Notebook, you'll want to temporarily turn the default style\n",
    "back on to get ticks back, like this:\n",
    "```\n",
    "with plt.style.context(\"default\"):\n",
    "    plt.imshow(image)\n",
    "```\n",
    "Also, like the erosion value, you can set any of these to \n",
    "`None` if you think you might not need them.\n",
    "\n",
    "As before, you may want to adjust `THRESHOLD` or `EROSION_SIZE`\n",
    "if you find that the algorithm isn't finding Moon labels well\n",
    "even if you have good settings for the label filter parameters.\n",
    "\n",
    "Visualizing individual labels using `labelstencil()`,\n",
    "`mask2shape()`, or similar may also be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e50cb-073e-49d8-a279-3016d0b16b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIN_WIDTH = some number\n",
    "# MIN_HEIGHT = some number\n",
    "# EDGE_SIZE = some number\n",
    "\n",
    "results = [\n",
    "    fullness_algorithm_4(\n",
    "        image, THRESHOLD, EROSION_SIZE, MIN_WIDTH, MIN_HEIGHT, EDGE_SIZE\n",
    "    )\n",
    "    for image in images\n",
    "]\n",
    "status_print = '\\n'.join([r['status'] for r in results])\n",
    "print(f\"STATUSES\\n{status_print}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2da0b8-cb29-4024-8b68-03c910d2c68f",
   "metadata": {},
   "source": [
    "### Algorithm step 5: Smooth the label and create a cutout from the image\n",
    "\n",
    "We'll next take a cutout around the label so that we can work with \n",
    "_just_ the part of the source image that contains the Moon. \n",
    "\n",
    "Then, before actually comparing the label to a bounding circle, \n",
    "we'll want to process it a little. This is because it's likely that \n",
    "many labels the algorithm selects, even when they accurately correspond \n",
    "to the Moon, will have little holes or jagged edges that will skew \n",
    "this comparison low, making the Moon look less illuminated than it really was.\n",
    "To help counteract this, we'll apply a binary dilation operator to help smooth\n",
    "and connect the label -- but we don't want to make its footprint too big,\n",
    "because that can distort the shape too.\n",
    "\n",
    "We can do this with the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ac5ba-1c0c-4a88-9daf-e86e96c38f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(image, dilation_size):\n",
    "    if dilation_size is None:\n",
    "        return image\n",
    "    return ndi.binary_dilation(image, np.ones((dilation_size, dilation_size)))\n",
    "\n",
    "def cut_around_indices(image, indices, cutout_margin):\n",
    "    \"\"\"\n",
    "    `indices` should be a single value from the `label_indices` dict\n",
    "    returned by `indexed_label()` specifying the x/y coordinates occupied\n",
    "    by a specific label.\n",
    "    \"\"\"\n",
    "    min_x = max(indices['x'].min() - cutout_margin, 0)\n",
    "    max_x = min(indices['x'].max() + cutout_margin, image.shape[1])\n",
    "    min_y = max(indices['y'].min() - cutout_margin, 0)\n",
    "    max_y = min(indices['y'].max() + cutout_margin, image.shape[0])\n",
    "    cutout = image[min_y:max_y, min_x:max_x]\n",
    "    # indices of label relative to the cutout\n",
    "    cutout_indices = {'x': indices['x'] - min_x, 'y': indices['y'] - min_y}\n",
    "    return cutout, cutout_indices\n",
    "\n",
    "\n",
    "def make_mask_and_cutout(\n",
    "    image, moonlabel_indices, dilation_size, cutout_margin\n",
    "):\n",
    "    # A cutout from the original image and the indices\n",
    "    # of the label within that cutout relative to the\n",
    "    # boundaries of the cutout.\n",
    "    cutout, cut_indices = cut_around_indices(\n",
    "        image, moonlabel_indices, cutout_margin\n",
    "    )\n",
    "    # A boolean array of the same dimensions as the cutout\n",
    "    moonmask = np.full(cutout.shape, False)\n",
    "    # set moonmask to True where the Moon label is present, \n",
    "    # False elsewhere.\n",
    "    moonmask[cut_indices['y'], cut_indices['x']] = True\n",
    "    return cutout, dilate(moonmask, dilation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf5aa5-04a2-43df-904d-410f1490053c",
   "metadata": {},
   "source": [
    "### Add dilation and cutout to handler function\n",
    "\n",
    "As previously, we can just add these to the end of `fullness_algorithm()`,\n",
    "and include their results in the output dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab9162-467c-4d0c-a0d7-522e0b7f01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullness_algorithm_5(\n",
    "    image,\n",
    "    threshold, \n",
    "    erosion_size,\n",
    "    min_width,\n",
    "    min_height,\n",
    "    edge_size,\n",
    "    dilation_size,\n",
    "    cutout_margin\n",
    "):\n",
    "    outline = make_outline(image, threshold)\n",
    "    eroded = erode(outline, erosion_size)\n",
    "    labels, label_indices = indexed_label(eroded)\n",
    "    label_statuses = check_labels(\n",
    "        label_indices, image.shape, min_width, min_height, edge_size\n",
    "    )\n",
    "    # 'status' is the overall status of the algorithm.\n",
    "    # 'moonlabel' is the number of the label the algorithm identified as \n",
    "    # corresponding to the Moon, or None if it didn't find the Moon.\n",
    "    status, moonlabel = filter_labels(label_statuses)\n",
    "    output = {\n",
    "        \"status\": status,\n",
    "        \"moonlabel\": moonlabel,\n",
    "        \"label_statuses\": label_statuses,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "    # We can't continue if we can't identify the Moon.\n",
    "    if status != \"ok\":  \n",
    "        return output\n",
    "    cutout, moonmask = make_mask_and_cutout(\n",
    "        image, label_indices[moonlabel], dilation_size, cutout_margin\n",
    "    )\n",
    "    return output | {'moonmask': moonmask, 'cutout': cutout}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43dbbf-4692-4886-8c06-1d6594c7b8ed",
   "metadata": {},
   "source": [
    "### Tune cutout margin and dilation size\n",
    "\n",
    "This is another parameter-tuning task, this time for `DILATION_SIZE` \n",
    "and `CUTOUT_MARGIN`. `CUTOUT_MARGIN` is partly a matter of taste -- \n",
    "making it too big won't make the algorithm fail, but will make it \n",
    "harder to examine the results.\n",
    "\n",
    "As always, if you don't like what you're seeing here, you may want to go\n",
    "back and change parameters from earlier steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cb807-b9d4-4a2a-8f8b-89fe7b0fa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DILATION_SIZE = some number\n",
    "# CUTOUT_MARGIN = some number\n",
    "\n",
    "results = [\n",
    "    fullness_algorithm_5(\n",
    "        image, \n",
    "        THRESHOLD, \n",
    "        EROSION_SIZE, \n",
    "        MIN_WIDTH, \n",
    "        MIN_HEIGHT, \n",
    "        EDGE_SIZE,\n",
    "        DILATION_SIZE,\n",
    "        CUTOUT_MARGIN\n",
    "    )\n",
    "    for image in images\n",
    "]\n",
    "\n",
    "cutouts = [r['cutout'] for r in results if r['status'] == 'ok']\n",
    "masks = [r['moonmask'] for r in results if r['status'] == 'ok']\n",
    "imshow_multiple(cutouts)\n",
    "_ = imshow_multiple(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85181bd-df07-4076-98c8-58392913ad85",
   "metadata": {},
   "source": [
    "## Algorithm step 6: calculate fullness\n",
    "\n",
    "The next cell completes the `fullness_algorithm()` function by adding circle comparison \n",
    "and an option to _not_ return all the label arrays, which will be important for running \n",
    "the function on all the images without using up too much memory. \n",
    "\n",
    "There aren't any new parameters to tune here: we're just drawing circles, comparing\n",
    "areas, and looking at the results. \n",
    "\n",
    "There aren't any new parameters to tune, but if the results don't look plausible to \n",
    "you, go back and change other parameters until they seem at least ok. We'll do \n",
    "actual comparison to \"ground truth\" in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fd154-8678-41b9-bef1-e20d2335a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_circle(mask):\n",
    "    \"\"\"\n",
    "    Draw a bounding circle around a mask made from a label. \n",
    "    Compare the area of the mask to the area of that circle.\n",
    "    Return the computed area ratio, and a representation of \n",
    "    that circle drawn on the mask.\n",
    "\n",
    "    TODO: see if this is notably worse than using the area of\n",
    "    the hull. Add hull back if so, like:\n",
    "    hull = cv2.convexHull(mask2vec(mask))\n",
    "    ratio = cv2.contourArea(hull) / (np.pi * params['r'] ** 2)\n",
    "    \"\"\"\n",
    "    umask = mask.astype(\"u1\") \n",
    "    mask_area = umask.sum()\n",
    "    params, circle = mask2shape(umask, draw_on_array=True)\n",
    "    return mask_area / (np.pi * params['r'] ** 2), circle\n",
    "\n",
    "\n",
    "def fullness_algorithm(\n",
    "    image,\n",
    "    threshold, \n",
    "    erosion_size,\n",
    "    min_width,\n",
    "    min_height,\n",
    "    edge_size,\n",
    "    dilation_size,\n",
    "    cutout_margin,\n",
    "    return_labels = False\n",
    "):\n",
    "    outline = make_outline(image, threshold)\n",
    "    eroded = erode(outline, erosion_size)\n",
    "    labels, label_indices = indexed_label(eroded)\n",
    "    label_statuses = check_labels(\n",
    "        label_indices, image.shape, min_width, min_height, edge_size\n",
    "    )\n",
    "    # 'status' is the overall status of the algorithm.\n",
    "    # 'moonlabel' is the number of the label the algorithm identified as \n",
    "    # corresponding to the Moon, or None if it didn't find the Moon.\n",
    "    status, moonlabel = filter_labels(label_statuses)\n",
    "    output = {\n",
    "        \"status\": status,\n",
    "        \"moonlabel\": moonlabel,\n",
    "        \"label_statuses\": label_statuses,\n",
    "    }\n",
    "    # these will use up a lot of memory.\n",
    "    if return_labels is True:\n",
    "        output[\"labels\"] = labels\n",
    "    # We can't continue if we can't identify the Moon.\n",
    "    if status != \"ok\":  \n",
    "        return output\n",
    "    cutout, moonmask = make_mask_and_cutout(\n",
    "        image, label_indices[moonlabel], dilation_size, cutout_margin\n",
    "    )\n",
    "    fullness, circle = compare_to_circle(moonmask)\n",
    "    return output | {\n",
    "        'moonmask': moonmask, 'cutout': cutout, 'circle': circle, 'fullness': fullness\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28023064-1e59-4a1a-8f5c-f8c2003e0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full algorithm and visualize the results.\n",
    "\n",
    "results = [\n",
    "    fullness_algorithm(\n",
    "        image, \n",
    "        THRESHOLD, \n",
    "        EROSION_SIZE, \n",
    "        MIN_WIDTH, \n",
    "        MIN_HEIGHT, \n",
    "        EDGE_SIZE,\n",
    "        DILATION_SIZE,\n",
    "        CUTOUT_MARGIN\n",
    "    )\n",
    "    for image in images\n",
    "]\n",
    "\n",
    "ok = [r for r in results if r['status'] == 'ok']\n",
    "ratios = [r['fullness'] for r in ok]\n",
    "imshow_multiple([r['cutout'] for r in ok])\n",
    "_ = imshow_multiple(\n",
    "    [r['circle'] for r in ok], \n",
    "    titles=[f\"{round(r['fullness'] * 100, 1)}%\" for r in ok]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
