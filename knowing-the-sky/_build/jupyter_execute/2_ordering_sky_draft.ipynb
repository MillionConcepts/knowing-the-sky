{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45489af",
   "metadata": {},
   "source": [
    "## Lesson 2: Ordering the Sky\n",
    "#### Learning Objectives:\n",
    "After completing this lesson, users will be able to:\n",
    "1. Describe array and table data types and their uses\n",
    "2. Utilize python packages to open array and table data as represented by the data providers\n",
    "3. Index and manipulate data within arrays and tables\n",
    "\n",
    "_Python libraries introduced in this lesson:_ astropy.io.fits, matplotlib, numpy, os, pathlib, astroquery, requests, gzip, io, tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986821e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Standard Library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# third-party imports\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c1aaf-7fcc-417f-8a15-45bdf6e7c17b",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In our last lesson, we aquired data from online NASA repositories to begin an investigation to identify which stars were being referred to by the Salish individual(s) interviewed by Claude Schaffer:\n",
    "\n",
    ">There was a group of three stars that rose from the place that was between the sun and the moon and it never changed its positon of rising.\n",
    "\n",
    "In this lesson, we'll learn how to read that data into python standard objects and the basics of how to work with them. The two main types of data we'll cover in this lesson are arrays and tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9f81c",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "\n",
    "Arrays are one of the most important data structures in scientific programming, and, for that matter, practical mathematics more generally -- they are a basic pattern used in many systems and cultures. Computers are very good at working with them, so knowing how to manipulate them effectively is extremely powerful. If you are reading this, it is entirely possible you have extensive experience with array data. Things may be different in Python than other languages, though, so we recommend not skipping it.\n",
    "\n",
    "#### What is an array?\n",
    "\n",
    "Basically, an array is simply a regular grid of 'elements', which are often but not always numbers. It can be 1-D, 2-D, 3-D, or even more. A 1-D array is a lot like a list. \n",
    "\n",
    "You can access elements in an array by coordinates, which means that they work like coordinate spaces. This is *very* useful for scientific programming. You can also perform mathematical operations on an entire array at once, which is both convenient and typically much faster than performing the same operations on each element one-by-one.\n",
    "\n",
    "(footnote for the mathematically inclined): an array is *not* a vector, matrix, or tensor, but it can be used to *represent* a vector, matrix, or tensor. \n",
    "\n",
    "#### How do you work with arrays in Python?\n",
    "\n",
    "`numpy` is the most common library for creating and manipulating arrays. Most scientific programs use `numpy` at some point, partly because many other libraries use it 'under the hood'. A very important point is that raster images (images made up of pixels, as opposed to vector images) can always be converted to and from arrays, which means that arrays let you do very powerful image manipulation. Let's start with a very quick introduction to the most important parts of the `numpy` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a1dd1-e36d-4187-8d40-63a1a3c63055",
   "metadata": {},
   "source": [
    "First, let's make a little 4x4 triangular array we can play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61cf8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle = np.tri(4)\n",
    "triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13b437-3d14-45f9-a945-9e47b29cfc90",
   "metadata": {},
   "source": [
    "You can access single elements of an array by entering their coordinates in slice `[]` notation -- much \n",
    "like a Python list but with possible extra dimensions.\n",
    "\n",
    "A reminder that python is \"zero-indexed\" meaning when you are counting elements in an array, list, etc. You start from 0 not 1. (This is one of the major differences between Python and MatLab!)\n",
    "\n",
    "For a 2-D array, the row (y-axis) always goes first, then the column (x-axis). You get exactly the elements you specify, which means that yif you don't enter a number for every dimension, you can pick more than one element at a time. For instance, `[0]` means \"all the elements with 0-coordinate on the y-axis\", or, in other words, the first row. `[:,0]` (`:` is numpy's placeholder) means \"all the elements with 0-coordinate on the x-axis\", and returns the first column. If you specify a number for every dimension you can get just a single elements: `[0,0]` means \"the number\n",
    "in the upper-left corner\".\n",
    "\n",
    "Let's test this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7feda94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0.]), array([1., 1., 1., 1.]), 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle[0], triangle[:, 0], triangle[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910e0d1-56ea-4863-8162-27e299448d0b",
   "metadata": {},
   "source": [
    "You can also specify ranges. For instance, `[0:2, 0:2]` means \"give me the square in the upper left corner of size (2,2)\". \n",
    "\n",
    "Note here that the range is exclusive of the final index you're entering. In other words, you'll get rows/columns indexed 0-1, not data from row/column 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b2a66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle[0:2, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccec8e0-4621-4aa9-85b3-5f8535f14fe9",
   "metadata": {},
   "source": [
    "When working with arrays you read in from data, you won't always know what shape it is because you won't have made it like we did above. In numpy, `shape` can be used to return how many elements an array has along each of its dimensions. It's important to know an array's shape for a variety of reasons, but on eo fhtem is to know exactly how much there is to slice. Let's return our array's shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56267f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ff563-a501-4565-8f2d-5dafce56d87d",
   "metadata": {},
   "source": [
    "Remember that Python is 0-indexed, and that `.shape` returns the _number of elements_, not the index. That means this will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb6ddaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtriangle\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "triangle[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1431915-7cbb-46da-89a9-57c896b0af6c",
   "metadata": {},
   "source": [
    "Slice notation can also be used to set elements. If you do the same things we've been doing, but add an assignment (`=`), you can set all the values to a number -- or even set to the contents of another array, if it's the right size.\n",
    "\n",
    "This will set all the elements of the first row to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a590a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., 2.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle[0] = 2\n",
    "triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e23eb-1349-4899-837c-b1ab1e911315",
   "metadata": {},
   "source": [
    "If you do an arithmetic operation on an array with a scalar (like a single number), it will apply that operation to ever element of the array. Unlike slice assignment, this does not modify the array in place unless you use a special operator. It retuns a copy, leaving the original array unchanged. \n",
    "\n",
    "For instance, to get a copy of the array with every element doubled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c51e87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4., 4.],\n",
       "       [2., 2., 0., 0.],\n",
       "       [2., 2., 2., 0.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double = triangle * 2\n",
    "double"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12b2e8-efab-4f37-99f2-f5ee79d5e978",
   "metadata": {},
   "source": [
    "Doing arithmetic using two array perfoms the operation elementwise -- elements with matching indexes from each array. Let's create a random array to test this with. We'll use [`np.random.randint`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html) to create an array of random whole numbers between 0-10 the same shape as triangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5207c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 2, 5],\n",
       "       [5, 9, 3, 5],\n",
       "       [9, 8, 5, 7],\n",
       "       [2, 6, 8, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randarray = np.random.randint(0,10,size=triangle.shape)\n",
    "randarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed96b87-45ce-4ae9-a223-f50b7f3daa7d",
   "metadata": {},
   "source": [
    "and then multipy it by triangle..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37006132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14., 14.,  4., 10.],\n",
       "       [ 5.,  9.,  0.,  0.],\n",
       "       [ 9.,  8.,  5.,  0.],\n",
       "       [ 2.,  6.,  8.,  3.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randarray * triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d71fd-5c1f-4e97-a181-2c844908cc96",
   "metadata": {},
   "source": [
    "This doesn't work if you try to multiply two arrays with mis-matched shapes! Let's test this by trying to multipy a 3 x 3 array of 3 by triangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c42ca7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3],\n",
       "       [3, 3, 3],\n",
       "       [3, 3, 3]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three = np.full((3, 3), 3)\n",
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa7725d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (4,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mthree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtriangle\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (4,4) "
     ]
    }
   ],
   "source": [
    "three * triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82109cf3-0907-4871-b95e-7d002db65842",
   "metadata": {},
   "source": [
    "As expected, we get an error. But if we slice our larger array to be the same shape as our 3x3 array we can multiply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8207f741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6.],\n",
       "       [3., 3., 0.],\n",
       "       [3., 3., 3.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three * triangle[0:3, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df10904-dd94-476f-b051-da9f306f59e9",
   "metadata": {},
   "source": [
    "You can even do assignment like this! This will multiply the upper-left 3x3 square of `triangle` by `three`, in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "026df528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6., 2.],\n",
       "       [3., 3., 0., 0.],\n",
       "       [3., 3., 3., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle[0:3, 0:3] = three * triangle[0:3, 0:3]\n",
    "triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff44790-2c4f-4647-af37-9086d781a130",
   "metadata": {},
   "source": [
    "Finally, you can also slice an array _with_ another array. This can get complicated fast: `numpy` calls it \"fancy indexing\" for a reason. However, there are a lot of very simple ways to use it. This most common one is to just select all the elements of an array tha tmeet some condition. For instance, this means \"pick all the elements of triangle that are less than 3\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0dfc4a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 0., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle[triangle < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dca87d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Loading images\n",
    "\n",
    "Ok, intro examples over; let's take a look at something more practical. We'll load a FITS image into memory using `astropy.io.fits` and look at some basic ways to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dddfe5bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'placeholder_images/e23456-nd-t0060-b00-f0008-r.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: placeholder image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# FITS files consist of multiple header-data units, or HDUs. Each HDU\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# object, which in most cases can simply be treated as a Python list with\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# some extra useful methods, like .info().\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m hdul \u001b[38;5;241m=\u001b[39m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplaceholder_images/e23456-nd-t0060-b00-f0008-r.fits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m hdul\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[0;32m~/mambaforge/envs/topst/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:213\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/topst/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:476\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    468\u001b[0m ):\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/topst/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:1146\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m~/mambaforge/envs/topst/lib/python3.10/site-packages/astropy/io/fits/file.py:217\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m~/mambaforge/envs/topst/lib/python3.10/site-packages/astropy/io/fits/file.py:626\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    623\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'placeholder_images/e23456-nd-t0060-b00-f0008-r.fits'"
     ]
    }
   ],
   "source": [
    "# TODO: placeholder image\n",
    "\n",
    "# FITS files consist of multiple header-data units, or HDUs. Each HDU\n",
    "# includes a header area containing metadata and a data area containing,\n",
    "# unsurprisingly, data. This data can be an array or a table. In this case,\n",
    "# all HDUs are arrays. astropy.io.fits loads FITS files into an HDUList\n",
    "# object, which in most cases can simply be treated as a Python list with\n",
    "# some extra useful methods, like .info().\n",
    "hdul = fits.open('placeholder_images/e23456-nd-t0060-b00-f0008-r.fits')\n",
    "hdul.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see from the () dimensions entry, HDU 0 contains no actual\n",
    "# data -- it's a placeholder to help organize the rest of the file.\n",
    "# HDU 1, however, contains an actual array. Let's go ahead and get the\n",
    "# data from it:\n",
    "hdu = hdul[1]\n",
    "image = hdu.data\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612f223",
   "metadata": {},
   "source": [
    "### Exploring arrays\n",
    "\n",
    "As we saw earlier, the representation `numpy` provides for arrays is excellent for small arrays. Unfortunately, as we can see here, for large arrays, it doesn't really tell you much except the data type **todo: should we have a section on data types?** and what's in the corners. Fortunately, Python offers many tools for summarizing and visualizing arrays. \n",
    "\n",
    "#### Dealing with nonfinite values\n",
    "\n",
    "Before we start exploring, we need to deal with the fact that lots of scientific data -- including this image -- contain 'nonfinite' values: `nan` (not-a-number, sometimes called 'null', used for missing or invalid entries), `inf` (infinity), and `-inf` (negative infinity). This means many statistical tools will fail on them out of the box: what, after all, is the mean of 2, 3, and not-a-number? There are several ways to work with data despite nonfinite values. The most powerful tool `numpy` provides is the masked array, which allows you to ignore specific elements and work with the array just like you would otherwise. A caveat: not all libraries 'respect' masked arrays, so you may have to do fancier tricks when working with some tools. However, many do. We'll show a common trick for dealing with libraries that don't a little further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean does not provide a useful result on the original array:\n",
    "np.mean(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# however, if we construct an array that masks all nonfinite elements, we're in business:\n",
    "image = np.ma.masked_invalid(image)\n",
    "np.mean(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22616e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go ahead and also mask everything below 0 (0 is valid minimum for this image).\n",
    "# the mask is just an array of boolean (True/False) values, and you can slice and assign\n",
    "# it just like any other array. we'll use the fancy indexing trick from above:\n",
    "image.mask[image < 0] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26dcb8",
   "metadata": {},
   "source": [
    "#### Summarizing arrays\n",
    "\n",
    "`numpy` offers many built-in tools that are good for simply describing arrays as well as performing mathematical operations. Commonly-useful ones include `std` (standard deviation), `mean`, and `median`. We just looked at `mean`. Let's look at the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a25527",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    np.std(image), \n",
    "    # using the version from the np.ma namespace because of a little glitch in core numpy\n",
    "    np.ma.median(image)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d750f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these can also be used along an individual axis. for example, if you'd like the mean of every column:\n",
    "np.mean(image, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca67d85",
   "metadata": {},
   "source": [
    "#### Outside of numpy\n",
    "\n",
    "For really serious statistical work, it's often useful to turn to `scipy.stats`, which has a wide range of useful tools. `scipy.describe` is great for getting a bunch of basic descriptive statistics at once, *usually*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedddf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.describe(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmmm...that's a lot of nans, and it worked along only one axis, which probably isn't what \n",
    "# we wanted. here's a little trick for getting just the unmasked elements of an array, \n",
    "# 'raveled' into a single dimension:\n",
    "valid = image[~image.mask]\n",
    "stats.describe(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba4c25",
   "metadata": {},
   "source": [
    "### Visualizing arrays\n",
    "\n",
    "Since many arrays are images, we often want to simply *look* at them. This, of course, can even be useful for arrays that _aren't_ exactly images. There are many ways to do this, but the `imshow` function from `matplotlib.pyplot` is one of the most straightforward: it simply plots a 1D, 2D, or 3D array on a grid. Let's use it to take a look at the image we just opened -- although the results may not be satisfying at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, plt.imshow, by default, applies a linear 'stretch' to the image. Because the range\n",
    "# of values in this image are so wide, it doesn't look like much at all -- almost everything is at the\n",
    "# lower extreme of the color scale.\n",
    "# let's write a little function that uses numpy to range-clip the image so we can look at it more clearly.\n",
    "\n",
    "def std_clip(array, sigma=1):\n",
    "    # find the mean and standard deviation of the array\n",
    "    mean, std = np.mean(array), np.std(array)\n",
    "    # restrict the bounds of the array to (mean - sigma * std, mean + sigma * std)\n",
    "    return np.clip(array, mean - sigma * std, mean + sigma * std)\n",
    "\n",
    "clipped = std_clip(image)\n",
    "plt.imshow(clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a2efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because we made sigma variable, we can modify the stretch however we like.\n",
    "# if we'd like a brighter (but noisier) image:\n",
    "really_clipped = std_clip(image, sigma=0.25)\n",
    "plt.imshow(really_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing works very well on arrays considered as images. for instance, you can use\n",
    "# it to take a 'cutout' from an image to look at a portion in detail:\n",
    "plt.imshow(clipped[1000:1200, 1000:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cd26b",
   "metadata": {},
   "source": [
    "## Tables\n",
    "Tables are basically arrays.\n",
    "\n",
    "### Ok, but what is a table, really?\n",
    "A table is _like_ an array, with the following differences:\n",
    "* 'Table' implies 2-D: it has rows and columns and nothing else.\n",
    "* The columns of a table are also called 'fields', and have\n",
    "    *meanings* that are distinct from one another: for instance, a table created from a radiometer \n",
    "    on a satellite might have fields representing time, latitude, longitude, and brightness temperature;\n",
    "    individual rows would represent individual observations.\n",
    "    * This is different from arrays, where, in general, every element has a roughly equivalent *meaning*, but in a different *place*.\n",
    "* A table can have more than one data type: for instance, a star catalog might have a field representing\n",
    "    right ascension in 64-bit floating-point numbers, and a field representing star names as strings.\n",
    "* **todo: maybe not necessary here** A table also generally has an 'index', which can be \n",
    "    a numerical series that simply corresponds to row number, but can be something else\n",
    "    entirely -- for instance, a table of personnel data might be indexed by employee ID number.\n",
    "\n",
    "Like arrays, tables are of ancient origin and found in many forms in many contexts, but computers really like to work with them. Tables are even more widely used than arrays in general-purpose computing. Common examples include spreadsheets and SQL databases. The world runs on tables.\n",
    "\n",
    "### Tabular file formats\n",
    "\n",
    "#### Broad categories: binary vs. text\n",
    "Tables can be stored in many formats. The two major _categories_ of format are binary and text tables. Text table formats store values as human-readable strings, like:\n",
    "\n",
    "| RA | DEC |\n",
    "| ------ | ----- |\n",
    "| 17.222 | -12.301 |\n",
    "| 17.223 | -12.311 |\n",
    "| 17.222 | -12.323 |\n",
    "\n",
    "These sorts of tables are relatively easy to look at and manipulate in spreadsheet programs or text editors -- unless they get so big that the program will refuse to load them!\n",
    "\n",
    "By contrast, binary table formats store values as raw bytes. The number of bytes per entry depends on the underlying data type. They are poorly human-readable, but tend to use less disk space and be quicker to load than text tables. As 32-bit floating point numbers expressed in bytes, the preceding table might look like:\n",
    "| | |\n",
    "|-|-|\n",
    "| \\xa8\\xc6\\x89 | \\xe5\\xd0D\\xc1 |\n",
    "| \\xb4\\xc8\\x89A | \\xe5\\xd0D\\xc1 |\n",
    "| \\xa8\\xc6\\x89 | \\x02+E\\xc1 |\n",
    "\n",
    "This is about 50% smaller in terms of data volume than the text version, but most people are not going to get much out of just _looking_ at it, and trying to manipulate it by copy-pasting would be fruitless. To use it, you need to load it into software that will translate it into meaningful numbers.\n",
    "\n",
    "Some binary table formats simply contain encoded values. Other formats embed metadata along with the values (for instance, cell colors in an Excel file). These formats tend to be harder to read.\n",
    "\n",
    "The upshot of all this is that really large tables -- tables that you wouldn't be able to visually scan, or maybe even successfully load, in a spreadsheet or text editor -- should almost always be stored in binary formats. Small tables are fine to store as text. If you're only planning to use them as intermediate data, though, small tables might also just as well be binary.\n",
    "\n",
    "#### Characteristics of some specific formats\n",
    "There are many, many tabular data formats. This is not an exhaustive list, but here are some common formats you are likely to encounter in planetary science and astronomy:\n",
    "\n",
    "**DSV (delimiter-separated value)**\n",
    "\n",
    "DSV is a family of text table formats that place each row on a separate line, and separates columns with a special delimiter character, usually a comma or a tab (a tab is represented by '\\t' in most programming languages). Comma-separated tables are often called CSV, and tab-separated TSV. This is a CSV table:\n",
    "```\n",
    "satellite,1.002,-379,True\n",
    "unknown,1.547,-22,False\n",
    "```\n",
    "Common file extensions for DSV files are .csv, .tsv, .txt, and .tab, but there are many others.\n",
    "\n",
    "\n",
    "**FWF (fixed-width file)**\n",
    "\n",
    "FWF is a text table format that places each row on a separate line, and separates columns by defining a specific 'width' -- number of characters -- for each column. These columns may also have whitespace 'padding' to make them easier to read (and for programs to figure out how to parse them if they don't have the definition available). FWF files were traditionally easier for programs to read than DSV files, but this is no longer true. In general, we recommend choosing DSV formats over FWF, because the delimiters make it easier for a wider variety of programs to parse them, they are usually a little smaller (because not every row has to be the same width), and you are less likely to make mistakes if you edit them manually. This is a fixed-width version of the DSV table above:\n",
    "```\n",
    "satellite 1.002 -379 True \n",
    "unknown   1.547 -22  False\n",
    "```\n",
    ".tab and .txt are common file extensions for FWF, but, like DSV, providers often exercise creativity.\n",
    "\n",
    "\n",
    "**Excel (and other spreadsheet formats)**\n",
    "\n",
    "Spreadsheet files are generally binary tables with embedded metadata that allow spreadsheet programs to retain formatting like fonts, cell colors, and sheet breaks. These are usually *proprietary* formats: although they can be reverse-engineered, the makers of the software do not publish specifications for them, and they are subject to change between software versions. This means that they are poorly portable and not very future-proof. For these reasons, we do not recommend exchanging scientific data in spreadsheet formats, and most spreadsheet software can easily export data in standard formats like CSV. Most spreadsheet formats have extensions that indicate the specific software used to produce them: for instance, Excel uses .xlsx or .xls.\n",
    "\n",
    "**FITS**\n",
    "\n",
    "FITS files, which were invented for astronomy but have seen widespread adoption in other scientific disciplines, can contain either binary or text tables (although FITS text tables are rarely used in practice). Because FITS files, as we discussed earlier, can have multiple HDUs, a single FITS file can contain multiple tables. FITS files usually have a .fits or .fit extension. We think FITS is one of the best ways to save tables due to its widespread support and mature, stable standard.\n",
    "\n",
    "**PDS binary tables**\n",
    "\n",
    "Many tabular data products in the PDS have ad-hoc structures they describe in external metadata. Standards differ between PDS3 and PDS4. In PDS3, structures can be defined in either their attached or detached PDS3 labels, or in an arbitrary number of distinct format (.fmt) files. In PDS4, binary table structure must be completely defined in a file's detached XML (.xml) label. Common extensions for these files include .dat and .tab.\n",
    "\n",
    "**SQL databases**\n",
    "\n",
    "**TODO: maybe skip this?**\n",
    "\n",
    "**Parquet**\n",
    "\n",
    "Parquet is a newer tabular interchange format that has seen wide adoption in industry and is increasingly common in scientific contexts. It is a _columnar_ format, which means that every field is stored in a distinct area and can be both compressed and readily accessed individually, which makes it very efficient for many purposes. We think Parquet is also an excellent choice for tabular data, especially very large tables that you don't want to load into memory all at once.\n",
    "\n",
    "**general-purpose data formats**\n",
    "\n",
    "Finally, while this category is much to broad to detail, it's worth noting that tables can also be represented in structured data formats that aren't specialized for tables, like Javascript Object Notation (JSON) and Extended Markup Language (XML). (In fact, Excel files rely in part on a compressed and modified version of XML!) Features of programming languages that save in-memory objects to disk, like Python `pickle` files or MATLAB .mat files, can similarly be used to store tables -- but then they can only be opened in that programming language! We don't recommend doing this unless you have a really good reason to.\n",
    "\n",
    "**TODO: maybe something about headers?**\n",
    "\n",
    "\n",
    "### Working with tables in Python\n",
    "\n",
    "There are many packages for working with tabular data in Python. `pandas` is by far the most common, and it's what we'll mostly use in this book. `pandas` has built-in support for reading and writing a wide variety of table formats, but not all, so you'll sometimes need to use a helper package to load data into `pandas`. For instance, `pandas` can't read FITS tables, so you'll need to go through a specialty FITS library like `astropy.io.fits` or `fitsio`. Similarly, to read tables described in PDS metadata, you'll need to use a library like `pdr` or `pds4-tools`.\n",
    "\n",
    "Also, as you saw in the previous lesson, people often compress table files 'monolithically', wrapping the whole file at once in a compression format like gzip. Some packages can decompress files like this automatically, but most can't, so you'll often need to decompress table files before you can use them.\n",
    "\n",
    "`pandas` is very, very powerful; however, it has many features that don't follow a common idiom, so it needs to be used with care. Let's move on to some basic ways to use `pandas`. We'll use the Bright Star Catalog as our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the BSC 'catalog' file has no file extension. However, if you open \n",
    "# it up in a text editor, you'll quickly see that:\n",
    "# 1. it is a text table, and\n",
    "# 2. it has no delimiter characters.\n",
    "# this means that it is a fixed-width file. \n",
    "# you'll also notice that a lot of the fields appear to run together,\n",
    "# which makes it somewhat hard to read -- both for humans and for\n",
    "# pandas. let's see what happens if we just use the pandas\n",
    "# read_fwf function, which attempts to read a FWF by inferring\n",
    "# the width of each field. The header=None argument tells pandas\n",
    "# that the table has no column headers.\n",
    "\n",
    "bsc_take_1 = pd.read_fwf('bright_star_directory/catalog', header=None)\n",
    "bsc_take_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, that looks _sort of_ reasonable. We can validate it by opening the specification of the table\n",
    "# in bright_star_catalog/ReadMe in a text editor...\n",
    "# And, unfortunately, if you scroll down to line 77, \"Byte-by-byte Description of file\",\n",
    "# you'll see that it's not correct. The specification gives over 50 columns, while pandas detected\n",
    "# only 14:\n",
    "bsc_take_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, we have a couple of options here. If you take a look at the read_fwf() documentation here,\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_fwf.html,\n",
    "# you'll see that you can pass a list of column specifications to read_fwf() in its colspecs argument.\n",
    "# however, we'd have to type all of those in, which is doable, but doesn't sound like much fun.\n",
    "# The easy direct download we used last time deceived us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's, instead, try to get this into pandas another way.\n",
    "# CNRS's Vizier service offers access to many complete catalogs. \n",
    "# Let's see if it's got the BSC.\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "catalogs = Vizier.find_catalogs('Bright Star Catalogue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, it's got 19 catalogs related to that search! Let's take a look at which specific one we want:\n",
    "{\n",
    "    c: r.description for c, r in catalogs.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like 'V/50' is our target. Let's go ahead and download the whole thing from Vizier.\n",
    "# by default, Vizier will only return 50 rows, and we want the whole table, so let's \n",
    "# make a new Vizier object with changed settings:\n",
    "big_vizier_fetcher = Vizier(row_limit=99999)\n",
    "tables = big_vizier_fetcher.get_catalogs([catalogs['V/50']])\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040c6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ae3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we've got the catalog _and_ the notes. let's look at the catalog.\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc44265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't have quite as many columns as the 'full' version, but they're separated correctly,\n",
    "# and we don't need most of that metadata. \n",
    "# you'll also note that astroquery.vizier returned this as an astropy Table object, but we'd rather\n",
    "# work with it in pandas. astropy Tables can be easily converted to pandas, so let's do that:\n",
    "bsc = tables[0].to_pandas()\n",
    "bsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929384af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's more like it! now, to prevent us from having to fetch it again,\n",
    "# let's write it out in a format pandas will be able to understand more easily --\n",
    "# a simple CSV file.\n",
    "# (the index=None argument means 'don't write the index as a separate column'.)\n",
    "bsc.to_csv('bright_star_directory/catalog.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49362c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's verify that we can read it in again:\n",
    "bsc_in = pd.read_csv('bright_star_directory/catalog.csv')\n",
    "bsc_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great. It looks the same, with one notable exception: it reinterpreted some\n",
    "# of the columns as numbers, which also caused it to fill in blank spaces with NaNs. \n",
    "# This is in fact a very good thing! for instance, if we'd wanted to look at all the\n",
    "# stars with Double Star Catalog designation (ADS) < 50, and had tried to do that on the \n",
    "# original table, we would have gotten an error, because Vizier specified that column\n",
    "# as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff44727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so what can we do with this object?\n",
    "# First, a little vocab: this object is called a DataFrame. \n",
    "# This is one of the two basic pandas types. The other basic pandas type\n",
    "# is a Series. Every field/column in a DataFrame is a Series:\n",
    "type(bsc_in), type(bsc_in['RAJ2000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5329898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like numpy, pandas has a lot of tools for accessing elements of a table,\n",
    "# but it works differently, principally because rows and columns can have\n",
    "# names, not just numbers.\n",
    "\n",
    "# pandas's core tools for this are called _indexers_, and it has three of them:\n",
    "# .at, .loc, and .iloc. .at is rarely used and we will ignore it; we will mostly \n",
    "# discuss .loc here.\n",
    "\n",
    "# .loc fetches one or more elements by name: index name(s) first, column name(s) second.\n",
    "# Like numpy, pandas uses ':' as a placeholder, and you don't have to give it both\n",
    "# index and column. Some examples:\n",
    "\n",
    "# this is the visual magnitude (Vmag) of stars 3000-3010:\n",
    "bsc_in.loc[3000:3010, 'Vmag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfc73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is everything in the 3000th row:\n",
    "bsc_in.loc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the Vmag of every star:\n",
    "bsc_in.loc[:, 'Vmag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply using slice notation right on the dataframe is an alias for .loc[:, column_name]:\n",
    "bsc_in['Vmag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d25ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll note that these last few gave Series objects rather than DataFrame objects.\n",
    "# this is because we only got a single row or column at once. It's possible to slice\n",
    "# a whole dataframe out of a dataframe. Because the columns have string names rather\n",
    "# than numbers, you can do this by passing a list. Here is the vmag and right ascension\n",
    "# of stars 30-40, presented as a dataframe:\n",
    "bsc_in.loc[30:40, ['Vmag', 'RAJ2000']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9236b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like numpy arrays, you can select elements of a DataFrame that meet some special condition.\n",
    "# the easiest way to do that is by defining a logical predicate. An expression like this\n",
    "# produces a boolean Series giving us only very bright stars with Vmag < 2:\n",
    "bright_predicate = bsc_in['Vmag'] < 2\n",
    "bright_predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbda8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then pass that Series to .loc in order to select all the rows\n",
    "# of the DataFrame for which that condition is true:\n",
    "bright = bsc_in.loc[bright_predicate]\n",
    "bright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed104492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like arrays, the values in DataFrames can be easily plotted with matplotlib.\n",
    "# for instance, to make a scatter plot of Vmag vs. color (B-V):\n",
    "plt.scatter(bsc_in['Vmag'], bsc_in['B-V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740838e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like arrays, you can assign values to particular elements of a DataFrame,\n",
    "# and you can do operations on big swaths of a DataFrame at once.\n",
    "# you'll note that there's some unnecessary padding in the 'Name' field:\n",
    "bsc_in.loc[2, 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's trim all that using a simple regex that will truncate all sequences of more than one space. \n",
    "bsc_in['Name'] = bsc_in['Name'].str.replace('  +', ' ', regex=True)\n",
    "bsc_in.loc[2, 'Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlike arrays, you can also just add new columns willy-nilly. Vmag is logarithmic in base ~2.512, so \n",
    "# if you wanted a linear version of it for some calculation, you could do this:\n",
    "bsc_in['Vmag_exp'] = 2.512 ** bsc_in['Vmag']\n",
    "bsc_in['Vmag_exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58be093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we don't really want it, so let's take a look at how we can easily drop that column:\n",
    "bsc_in = bsc_in.drop(columns='Vmag_exp')\n",
    "bsc_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also drop rows. There are a few entries in the BSC that don't have actual\n",
    "# coordinates. Let's clean them up quickly. Note that the '~' means 'not', so we're \n",
    "# saying: 'get rid of all the rows that don't have a real RAJ2000 value'.\n",
    "bsc_in = bsc_in.loc[~(bsc['RAJ2000'] == '')]\n",
    "# after you do this sort of thing, it's usually a good idea to copy the dataframe and reset the\n",
    "# index -- otherwise you can get confusing errors. (There are cases where this isn't\n",
    "# true, of course, but it's a good rule of thumb.) This is the easiest way to do it:\n",
    "bsc_in = bsc_in.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf95862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's one more thing we should do before we move on. The BSC gives RA and DEC\n",
    "# in sexigesimal notation. This is all well and good, but can be hard for general-purpose\n",
    "# tools to work with, because they don't usually understand this notation. Hence this error:\n",
    "bsc_in.loc[(bsc_in['RAJ2000'] < 20) & (bsc_in['DEJ2000'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortunately, astropy _does_ understand this notation, and we can use it to convert these\n",
    "# from sexigesimal to decimal. The Angle object from astropy.coordinates is our helper here.\n",
    "# note that you have to specify the units, or astropy will be unhappy.\n",
    "from astropy.coordinates import Angle\n",
    "ra0 = Angle(bsc_in.loc[0, 'RAJ2000'], unit='hour')\n",
    "# astropy parses and prints it nicely:\n",
    "ra0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then you can convert it from hour-minute-second to decimal degrees:\n",
    "ra0_decimal = ra0.degree\n",
    "ra0_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's all well and good for a single value -- but you can even pass the entire\n",
    "# Series at once...\n",
    "ra_angles = Angle(bsc_in['RAJ2000'], unit='hour')\n",
    "ra_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and convert it all to decimal at once!\n",
    "ra_decimal = ra_angles.degree\n",
    "ra_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the same thing with declination, which is in degree-minute-second\n",
    "# rather than hour-minute-second:\n",
    "dec_angle = Angle(bsc_in['DEJ2000'], unit='deg')\n",
    "dec_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf5fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_decimal = dec_angle.degree\n",
    "dec_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can go ahead and replace the ra/dec strings in the dataframe\n",
    "# with our decimal numbers.\n",
    "bsc_in['RAJ2000'] = ra_decimal\n",
    "bsc_in['DEJ2000'] = dec_decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e5905",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# and you'll find that our earlier expression will work:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}