{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good python import style organizes imports into three 'blocks' to make it easy\n",
    "# to diagnose import problems.\n",
    "\n",
    "# the first block contains imports from the Python Standard Library -- the modules \n",
    "# anyone with a Python install has access to.\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# the second block contains imports from other external modules -- code you're \n",
    "# using but not actively working on.\n",
    "from astroquery.vizier import Vizier \n",
    "import requests\n",
    "\n",
    "# the third block contains imports from modules you _are_ actively working on.\n",
    "# it's not present here, because we haven't written any modules yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb2f8c",
   "metadata": {},
   "source": [
    "### acquiring data\n",
    "\n",
    "Unless you're doing pure simulations --- and sometimes even then --- you'll usually need source data for scientific programming. Simply finding, acquiring, and figuring out how to 'open' data can take as much time as analyzing it. Fortunately, many excellent libraries and tools exist to make these tasks easier. \n",
    "\n",
    "The technology that underlies the following examples is called the Hypertext Transfer Protocol, or, more commonly, just HTTP -- an abbreviation that's probably familiar to you from your browser URL bar. HTTP is the primary \"application layer\" protocol used to access content on the Internet and to interact with online services, including cloud services. Applications use HTTP by issuing \"requests\" of various types, most commonly GET (retrieve data), PUT, and POST (which both send data). Servers respond to HTTP requests by sending HTTP \"responses\", which can contain both data and metadata about the response. HTTP metadata are called \"headers\".\n",
    "\n",
    "Most popular programming languages offer ways to make HTTP requests and interpret HTTP responses, and Python is no exception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0774f90",
   "metadata": {},
   "source": [
    "#### web data: requests\n",
    "\n",
    "Sometimes you'll find that the files you need are accessible via plain web links (URLs). If it's just a handful of files, a web browser may do the job just fine. If there are more --- especially if the URLs are regularly constructed, in a list you can load into memory, or subject to change based on other parts of your program --- it's often better to do it with code.\n",
    "\n",
    "`requests` is a popular library for making HTTP requests in Python. This first example is *very* easy.  We'll look at some more complex uses of `requests` in later modules.\n",
    "\n",
    "**todo: i'd like a more complex example --- something where we can use a for loop --- maybe in an exercise? hard to make it relevant for the first section, is the issue...but we could get other data they need.**\n",
    "\n",
    "We'll need information on stars people can see without optical equipment in order to **TODO: insert narrative content**, so let's grab a copy of the Bright Star Catalog, a popular catalog of stars visible from Earth with the naked eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef94ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for the catalog\n",
    "bright_star_url = \"http://cdsarc.u-strasbg.fr/viz-bin/nph-Cat/tar.gz?V/50\"\n",
    "\n",
    "# requests.get downloads a file from a url and returns a requests.Response object,\n",
    "# which contains both the file's contents and any headers sent by the server\n",
    "bright_star_response = requests.get(bright_star_url)\n",
    "\n",
    "# it's good to check whether you actually got the file. Response.raise_for_status\n",
    "# will raise an exception if the server returned a 404 (missing) or other error code.\n",
    "bright_star_response.raise_for_status()\n",
    "\n",
    "# Response.content contains the body of the response -- in this case, the catalog file.\n",
    "# Sometimes you can easily work with it in memory, especially if it can be decoded\n",
    "# as plain text. That isn't the case here, because it's a compressed .tar.gz file.\n",
    "# We'll look at how to decompress it later.\n",
    "# note that you don't want to print the whole response out in the Notebook, because it's 740 \n",
    "# kilobytes -- hundreds of pages of binary gibberish!\n",
    "# there are nevertheless some good ways to get some important information about it without getting \n",
    "# too complicated.\n",
    "print(f\"The response content is {len(bright_star_response.content)} bytes long.\")\n",
    "print(f\"It is a Python {type(bright_star_response.content)} object.\")\n",
    "print(f\"Here are the first 50 bytes of the response: {bright_star_response.content[:50]}.\")\n",
    "print(f\"The server says it is a {bright_star_response.headers['Content-Type']} file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900b8a9",
   "metadata": {},
   "source": [
    "#### catalog data: astroquery\n",
    "\n",
    "Many data aren't so easy to grab from plain URLs. Let's say we wanted to get some detailed images of a \n",
    "region of the sky from the Herschel mission. The Herschel image dataset is extremely large, and \n",
    "impractical to download in whole for most purposes. Fortunately, Herschel's images, like many data sets, \n",
    "are accessible via an Application Programming  Interface (API); unfortunately, APIs can be complicated to \n",
    "use, and every API is different. `astroquery`, an `astropy` affiliate package, is a grab-bag of high-level interfaces to APIs that attempt to solve this problem. Let's get an image of Orion with the help of `astroquery`'s \n",
    "`esasky` module.\n",
    "\n",
    "**note: consider this a placeholder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdbc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.esasky import ESASky\n",
    "maps = ESASky.query_object_maps('Alnitak', missions=['Herschel'])\n",
    "maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the URLs\n",
    "maps[0]['product_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951abaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO, maybe, if we wanted to show more cataloging...\n",
    "\n",
    "# import astropy.coordinates as coord\n",
    "# from astroquery.simbad import Simbad\n",
    "# result_table = Simbad.query_region(coord.SkyCoord(\"05h35m17.3s -05h23m28s\", frame='icrs'), radius='1d0m0s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c941c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### file management\n",
    "\n",
    "When working with scientific data, you'll often find yourself working with a large number of files, or with very large files. Both of these can present difficulties! Large numbers of files are difficult to organize. Individually large files can take a long time to download and open, and use up a lot of local storage space. Processing them without great care can use up a lot of your computer's working memory (RAM), leading to sluggish performance or even crashes. \n",
    "\n",
    "These problems are made worse by the fact that scientific files often have long, complicated filenames. Although they can contain a lot of useful information, they are hard to read until you are very used to a specific data set. \n",
    "\n",
    "It's also likely you'll find yourself writing a lot of files containing data you've processed with your own code.\n",
    "\n",
    "This all means that good file management is very important. It helps you avoid spending lots of time poking around and opening random files to find what you're looking for -- or, worse, losing your work.\n",
    "\n",
    "So, what is good file management? A lot of it comes down to personal preference or specific project needs, and there are many tools for it that you may find useful, but the most straightforward thing to do is to leverage the built-in capabilities of your filesystem, and that's what we'll do on this project. Filesystems are great! Every computer and every programming language knows how to work with them, and it is easy to click through folders in a file manager application and explore them with code. Here are some guidelines that work for most people:\n",
    "* Keep files for a specific project in a single folder 'tree'.\n",
    "* Name and organize folders in a way that makes sense to you -- keep similar files together and give folders names you will remember.\n",
    "* Similarly, choose a clear, expressive naming convention for any files you write yourself.\n",
    "* Don't put too many files in a single folder -- this makes it hard to browse and can also reduce performance. 100 is about the limit.\n",
    "* Keep code and data files in separate folders.\n",
    "* Make sure you know where new files are going. For example, when you download a file from the Internet using your browser, it often goes into a Downloads folder. It's good to know where that is in your filesystem so that you can actually use those files.\n",
    "* Keep new files that you write (output data) separate from files you've acquired from other sources (input data).\n",
    "\n",
    "The Python ecosystem, including just the Standard Library, has many tools to work with local filesystems. Let's look at a couple of common patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce579181",
   "metadata": {},
   "source": [
    "#### dealing with compression\n",
    "\n",
    "we have the Bright Star Catalog as an in-memory object -- not a file on disk. To use it in other scripts, we need to save it to disk.\n",
    "it's also compressed using gzip, a common compression algorithm, and _also_ 'wrapped' using tar, a common utility for compacting multiple files into a single file. these will make it hard to use straightforwardly, so let's unpack it in memory before we save it. this will also show you a number of useful patterns for working with compressed files and directories in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb49547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python's built-in package for handling gzip compression\n",
    "from gzip import GzipFile\n",
    "# BytesIO is an object that allows you to interact with an object\n",
    "# in memory as if it were a file\n",
    "from io import BytesIO\n",
    "# Python's built-in package for handling tar files\n",
    "from tarfile import TarFile, TarInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BytesIO must be initialized with a bytes object -- which we have in\n",
    "# bright_star_response.content!\n",
    "virtual_file = BytesIO(bright_star_response.content)\n",
    "# now we can initialize the GzipFile object using that virtual file.\n",
    "gzip_file = GzipFile(fileobj=virtual_file)\n",
    "# and now we can create an object to untar it!\n",
    "tar_file = TarFile(fileobj=gzip_file)\n",
    "files = tar_file.getmembers()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee525e3",
   "metadata": {},
   "source": [
    "#### fixing directory structures\n",
    "\n",
    "you'll note that these tar files are wrapped up in a less-than-optimal directory structure --\n",
    "the '.' means that if you try to just extract the whole archive with .extractall(),\n",
    "you'll get errors (because '././ReadMe', etc., are not legal directory names).\n",
    "you'll also note that two of them are still gzipped!\n",
    "so let's make a directory to write them into, and then write them by name,\n",
    "un-gzipping the ones we would prefer not to be gzipped as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathlib.Path objects are one of Python's most useful tools for working with the filesystem.\n",
    "# each one is an abstraction for a specific file or directory. they can be combined easily\n",
    "# to put files in a specific directory, and have a lot of convenience methods for manipulating\n",
    "# their names and reading or writing from disk.\n",
    "\n",
    "# this represents a subdirectory of your working directory called 'bright_star_directory'\n",
    "catalog_directory = Path(\"bright_star_directory\")\n",
    "# it probably doesn't exist yet, so let's make it -- the exist_ok argument is in case \n",
    "# you've run this cell before\n",
    "catalog_directory.mkdir(exist_ok=True)\n",
    "# let's verify it's there\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # get a buffer that contains the file data and read bytes out of it\n",
    "    file_bytes = tar_file.extractfile(file).read()\n",
    "    # define the actual path we want to write the file to.\n",
    "    # the '/' operator causes Python to combine the paths in the same way\n",
    "    # writing a / on the command line would.\n",
    "    # the 'replace' call makes sure we don't write an un-gzipped file\n",
    "    # with a '.gz' extension, which can cause issues.\n",
    "    target = catalog_directory / Path(file.name.replace('.gz', ''))\n",
    "    print(target)\n",
    "    # un-gzip if necessary:\n",
    "    if file.name.endswith('gz'):\n",
    "        file_bytes = GzipFile(fileobj=BytesIO(file_bytes)).read()\n",
    "    # 'with opehttp://localhost:8888/notebooks/topst_scratch/getting_data.ipynb#n(filename) as stream' is a very common pattern in Python.\n",
    "    # the 'with' means that it is a context manager. the indented block\n",
    "    # below it will operate using a temporary 'stream' argument that will\n",
    "    # automatically clean itself up when the block finishes running. this\n",
    "    # can prevent a lot of mess.\n",
    "    # 'wb' means that we are writing to the file, and writing in binary mode.\n",
    "    with open(target, 'wb') as stream:\n",
    "        stream.write(file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and just for fun, let's check to make sure that worked, using the same\n",
    "# pattern as before, but in read mode:\n",
    "with open('bright_star_directory/ReadMe') as stream:\n",
    "    print(stream.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# great! now we can move on to ways to use some of these files in \n",
    "# the next module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
